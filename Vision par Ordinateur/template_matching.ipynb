{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP2_templateMachine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Charger les deux images\n",
    "template = cv2.imread('X:\\\\Semestre_8\\\\Vision par ordinateur\\\\template_matching\\\\template.png')\n",
    "img = cv2.imread('X:\\\\Semestre_8\\\\Vision par ordinateur\\\\template_matching\\\\image.jpg')\n",
    "\n",
    "# Convertir l'image en niveau de gris\n",
    "template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Appliquer le template Matching\n",
    "method = cv2.TM_CCOEFF_NORMED\n",
    "res = cv2.matchTemplate(img_gray, template_gray, method)\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "# Récupérer les dimensions du template\n",
    "w, h = template_gray.shape[::-1]\n",
    "\n",
    "# Dessiner un rectangle autour du visage trouvé\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "# Afficher l'image finale avec le rectangle encadrant le visage\n",
    "cv2.imshow('Résultat de la corrélation avec rectangle', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La corrélation en traitement d'images mesure la similitude entre une image et un modèle. En OpenCV, différentes méthodes sont disponibles. Pour détecter des visages dans une image de groupe, la méthode TM_CCOEFF_NORMED fonctionne bien. Les méthodes TM_SQDIFF et TM_SQDIFF_NORMED peuvent être moins efficaces car elles cherchent le minimum de la différence entre les pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Charger le modèle (template)\n",
    "template = cv2.imread('X:\\\\Semestre_8\\\\Vision par ordinateur\\\\template_matching\\\\template_webcam.png')\n",
    "\n",
    "# Initialiser la webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capturer le frame de la webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Appliquer le template Matching\n",
    "    method = cv2.TM_CCOEFF_NORMED\n",
    "    res = cv2.matchTemplate(frame, template, method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "    # Récupérer les dimensions du template\n",
    "    w, h, _ = template.shape\n",
    "\n",
    "    # Dessiner un rectangle autour du visage trouvé\n",
    "    top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "    # Afficher le frame avec le rectangle encadrant le visage\n",
    "    cv2.imshow('Webcam', frame)\n",
    "\n",
    "    # Sortir de la boucle si la touche 'q' est pressée\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Libérer la webcam et fermer les fenêtres\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
