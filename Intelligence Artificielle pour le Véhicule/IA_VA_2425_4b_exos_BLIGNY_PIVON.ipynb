{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b713f62-706d-4114-96f7-4f308188f79b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <b>Exercice 4.4 : ResNet avec GTSRB</b>\n",
    "\n",
    "#### <b>a) Chercher à obtenir les meilleurs résultats possibles, avec un modèle pré-entraîné, pour 10 classes de GTSRB\n",
    "\n",
    "Pour le modèle, on utilisera la version <b>ResNet-18</b>.  \n",
    "Pour les classes, on choisira les suivantes :   \n",
    "- toutes les limitations de vitesse\n",
    "- stop\n",
    "- sens interdit\n",
    "\n",
    "Il suffit de reprendre ce qui a déjà été fait précedemment, mais en prenant un nombre plus important de classes.  \n",
    "\n",
    "- Essayer d'obtenir la meilleure précision possible (quitte à ajouter une couche cachée de neurones et à ajouter de l'augmentation du jeu de données d'apprentissage, si nécessaire).  \n",
    "- Tester le modèle sur au moins 2 images de classes différentes récupérées sur Internet (découpées à partir d'une image réelle comme dans l'exemple plus haut).\n",
    "\n",
    "Le code nécessaire devra être donné dans <b>2 cellules séparées</b> :\n",
    "- la 1ère pour l'apprentissage du modèle et sa sauvegarde dans un fichier\n",
    "- la 2e pour l'utilisation ultérieure du modèle à partir du chargement de ce fichier (avec mesure de la durée d'inférence)\n",
    "\n",
    "Chacune de ces 2 cellules devra fonctionner même après un redémarrage du kernel.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8295b9-1a43-439d-b204-80143a16088b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 200.3053, Accuracy: 80.25%\n",
      "Epoch 2/20, Loss: 56.5020, Accuracy: 95.18%\n",
      "Epoch 3/20, Loss: 30.6093, Accuracy: 97.63%\n",
      "Epoch 4/20, Loss: 32.5799, Accuracy: 97.21%\n",
      "Epoch 5/20, Loss: 22.3256, Accuracy: 98.22%\n",
      "Epoch 6/20, Loss: 16.4186, Accuracy: 98.61%\n",
      "Epoch 7/20, Loss: 19.9196, Accuracy: 98.54%\n",
      "Epoch 8/20, Loss: 18.1806, Accuracy: 98.67%\n",
      "Epoch 9/20, Loss: 11.9500, Accuracy: 99.05%\n",
      "Epoch 10/20, Loss: 17.0981, Accuracy: 98.83%\n",
      "Epoch 11/20, Loss: 10.9292, Accuracy: 99.14%\n",
      "Epoch 12/20, Loss: 9.0209, Accuracy: 99.32%\n",
      "Epoch 13/20, Loss: 9.6658, Accuracy: 99.31%\n",
      "Epoch 14/20, Loss: 9.8388, Accuracy: 99.34%\n",
      "Epoch 15/20, Loss: 16.6308, Accuracy: 98.99%\n",
      "Epoch 16/20, Loss: 10.6469, Accuracy: 99.30%\n",
      "Epoch 17/20, Loss: 12.6044, Accuracy: 99.21%\n",
      "Epoch 18/20, Loss: 10.8319, Accuracy: 99.24%\n",
      "Epoch 19/20, Loss: 7.2285, Accuracy: 99.50%\n",
      "Epoch 20/20, Loss: 7.5106, Accuracy: 99.49%\n",
      "Model saved to ex4.4.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration et device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Classes à conserver\n",
    "class_indices = [0, 1, 2, 3, 4, 5, 6, 7, 14, 17]  # Limitation de vitesse, stop, sens interdit\n",
    "class_names = ['speed_limit_20', 'speed_limit_30', 'speed_limit_50', 'speed_limit_60', \n",
    "    'speed_limit_70', 'speed_limit_80', 'speed_limit_100', 'speed_limit_120', \n",
    "    'stop', 'no_entry']\n",
    "\n",
    "# Transformation des images\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.RandomRotation(15),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Chargement des données filtrées pour les classes sélectionnées\n",
    "def load_filtered_data(data_path, class_indices):\n",
    "    images, labels = [], []\n",
    "    for idx in class_indices:\n",
    "        folder = f\"{data_path}/{format(idx, '05d')}\"\n",
    "        for img_path in glob(f\"{folder}/*.ppm\"):\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = transform(img)\n",
    "            images.append(img)\n",
    "            labels.append(class_indices.index(idx))  # Relabel pour les indices sélectionnés\n",
    "    return images, labels\n",
    "\n",
    "# Charger les données d'entraînement et de test\n",
    "data_path = '/home/jovyan/iadatasets/GTSRB/Final_Training/Images'\n",
    "images, labels = load_filtered_data(data_path, class_indices)\n",
    "dataset = list(zip(images, labels))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Modèle ResNet-18 pré-entraîné\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, len(class_indices))\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Critère et Optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entraînement et sauvegarde du modèle\n",
    "def train_and_save_model(model, train_loader, num_epochs=20, save_path=\"ex4.4.pth\"):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "# Entraînement et sauvegarde\n",
    "train_and_save_model(model, train_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed5eb4-a656-4fd9-b127-54faf50b617e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilisation du modèle pour des inférences sur de nouvelles images et calcul de la précision\n",
    "def load_and_infer_model(model_path, test_loader):\n",
    "    model = models.resnet18(pretrained=False)  # pretrained=False ici est correct pour charger les poids personnalisés\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(128, len(class_indices))\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Optionnel : Affichage des prédictions par image\n",
    "            for i in range(images.size(0)):\n",
    "                class_name = class_names[predicted[i].item()]\n",
    "                # print(f\"Image {i+1} - Predicted: {class_name}, Actual: {class_names[labels[i].item()]}\")\n",
    "\n",
    "    inference_time = time.time() - start_time\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Inference time: {inference_time:.4f} seconds for {total} samples\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432e2bc5-a067-4f5c-91b7-bd8a72add3ab",
   "metadata": {},
   "source": [
    "#### <b>Commentaires</b>\n",
    "\n",
    "Nous avons utilisé un modèle ResNet-18 pré-entraîné pour classifier 10 classes de panneaux. Pour améliorer la précision, nous avons ajouté une couche cachée et appliqué des augmentations de données (rotation, flip). Le modèle final a obtenu une précision satisfaisante en test, mesurée sur des images réelles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff796cb-cdd3-48b2-8e6a-4b62090cd162",
   "metadata": {},
   "source": [
    "#### <b>b) Idem a) avec toutes les classes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "119c0352-d880-4901-9618-91ba0e9f0740",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch 1/20, Loss: 747.2187, Accuracy: 76.49%\n",
      "Epoch 2/20, Loss: 216.5173, Accuracy: 93.13%\n",
      "Epoch 3/20, Loss: 149.7568, Accuracy: 95.66%\n",
      "Epoch 4/20, Loss: 119.2054, Accuracy: 96.51%\n",
      "Epoch 5/20, Loss: 99.8177, Accuracy: 97.18%\n",
      "Epoch 6/20, Loss: 78.0520, Accuracy: 97.91%\n",
      "Epoch 7/20, Loss: 75.9183, Accuracy: 98.06%\n",
      "Epoch 8/20, Loss: 58.6605, Accuracy: 98.47%\n",
      "Epoch 9/20, Loss: 61.1711, Accuracy: 98.49%\n",
      "Epoch 10/20, Loss: 54.5264, Accuracy: 98.57%\n",
      "Epoch 11/20, Loss: 47.6572, Accuracy: 98.90%\n",
      "Epoch 12/20, Loss: 43.5043, Accuracy: 98.94%\n",
      "Epoch 13/20, Loss: 52.4626, Accuracy: 98.83%\n",
      "Epoch 14/20, Loss: 34.9729, Accuracy: 99.22%\n",
      "Epoch 15/20, Loss: 39.6268, Accuracy: 99.01%\n",
      "Epoch 16/20, Loss: 28.0365, Accuracy: 99.27%\n",
      "Epoch 17/20, Loss: 29.6412, Accuracy: 99.30%\n",
      "Epoch 18/20, Loss: 36.1703, Accuracy: 99.20%\n",
      "Epoch 19/20, Loss: 21.6018, Accuracy: 99.54%\n",
      "Epoch 20/20, Loss: 32.7801, Accuracy: 99.30%\n",
      "Model saved to ex4.5.pth\n",
      "Test Accuracy: 98.99%\n",
      "Inference time: 7.2122 seconds for 7842 samples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import time\n",
    "\n",
    "# Configuration et device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Classes à conserver - toutes les classes du dataset\n",
    "class_indices = list(range(43))\n",
    "class_names = [f'class_{i}' for i in class_indices]  # Noms simplifiés pour chaque classe\n",
    "\n",
    "# Transformation des images\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.RandomRotation(15),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Chargement des données filtrées pour toutes les classes\n",
    "def load_all_data(data_path):\n",
    "    images, labels = [], []\n",
    "    for idx in class_indices:\n",
    "        folder = f\"{data_path}/{format(idx, '05d')}\"\n",
    "        for img_path in glob(f\"{folder}/*.ppm\"):\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img = transform(img)\n",
    "            images.append(img)\n",
    "            labels.append(idx)\n",
    "    return images, labels\n",
    "\n",
    "# Charger les données d'entraînement et de test\n",
    "data_path = '/home/jovyan/iadatasets/GTSRB/Final_Training/Images'\n",
    "images, labels = load_all_data(data_path)\n",
    "dataset = list(zip(images, labels))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Modèle ResNet-18 pré-entraîné\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, len(class_indices))\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Critère et Optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entraînement et sauvegarde du modèle\n",
    "def train_and_save_model(model, train_loader, num_epochs=20, save_path=\"ex4.5.pth\"):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "# Entraînement et sauvegarde\n",
    "train_and_save_model(model, train_loader, num_epochs=20)\n",
    "\n",
    "# Utilisation du modèle pour des inférences sur de nouvelles images et calcul de la précision\n",
    "def load_and_infer_model(model_path, test_loader):\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(model.fc.in_features, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(128, len(class_indices))\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    inference_time = time.time() - start_time\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Inference time: {inference_time:.4f} seconds for {total} samples\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Chargement et inférence\n",
    "model = load_and_infer_model(\"ex4.5.pth\", test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e09a3-7bdc-44cc-b807-9e9cf4273bbc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### <b>Commentaires</b>\n",
    "\n",
    "Dans cet exercice nous avons repris le modèle précédent que nous avons entrainé sur toutes les classes. Les modifications incluent l'adaptation des indices de classes et des noms de classes pour inclure toutes les catégories, ainsi que l'ajustement de la couche de sortie du modèle. Nous avons des résultats satisfaisants."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
